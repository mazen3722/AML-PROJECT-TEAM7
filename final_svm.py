# -*- coding: utf-8 -*-
"""final_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EvR3HC8g64efgJrV9pcVNLQFVDsQHDca
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score, KFold
import os
import pickle

def load_data(seed_dataset):
    df = pd.read_csv('seed_dataset.csv')
    # Perform data preprocessing steps
    return df




#read dataset
df = pd.read_csv('seed_dataset.csv')
df.shape

df

df.info()

#count the number of missing (NaN) values in each column of a dataset
df.isna().sum()

# describe object
df.describe(include='O')

# inplace change column in the actual dataset
df.replace({'Class':{'Çerçevelik':0,'Ürgüp Sivrisi':1}},inplace=True)
df

# Checking duplicated data
print('Number of duplicated data : ' , len(df[df.duplicated()]))

df.describe()

df.corr()

plt.figure(figsize=(10, 6))
sns.heatmap(df[['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Convex_Area', 'Equiv_Diameter', 'Eccentricity', 'Solidity', 'Extent', 'Roundness', 'Aspect_Ration', 'Compactness', 'Class']].corr(), annot=True, cmap='coolwarm')
plt.show()

# Columns that have high corr with some other columns
df = df.drop(['Convex_Area'],axis=1)
df = df.drop(['Equiv_Diameter'],axis=1)
df = df.drop(['Eccentricity'],axis=1)
df = df.drop(['Aspect_Ration'],axis=1)
df

# Box plot to visualize outliers
plotted_columns = df[['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Solidity', 'Extent', 'Roundness', 'Compactness']]
for col in plotted_columns.columns:
    plt.figure(figsize=(5,5))
    ax = sns.boxplot(df[col])
    ax.set_title(f'Distribution of {col} feature')
    plt.show()

def handle_outliers(dataframe, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

    df.loc[(df[col] > upper_bound), col] = df[col].astype(int)  # Assuming col is the column name
    df.loc[(df[col] < lower_bound,col)] = lower_bound

    return df
# Call function to return df_no_outliers
for col in df.select_dtypes(include=["number"]).columns :
    df = handle_outliers(df, col)

# Box plot to visualize outliers after cleaning the dataframe
for col in plotted_columns.columns:
    plt.figure(figsize=(5,5))
    ax = sns.boxplot(df[col])
    # f (format) we use it with variables
    ax.set_title(f'Distribution of {col} feature')
    plt.show()

df.var()

# # Normalization using log
# df["log_2_Area"] = np.log(df["Area"])
# df["log_2_Perimeter"] = np.log(df["Perimeter"])
# df["log_2_Major_Axis_Length"] = np.log(df["Major_Axis_Length"])
# df["log_2_Minor_Axis_Length"] = np.log(df["Minor_Axis_Length"])
# df

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = df.iloc[:, :-1]
y = df.iloc[:, -1]
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
df_scaled = pd.concat([X_scaled, y], axis=1)

df_scaled.var()

# Import train_test_split function
from sklearn.model_selection import train_test_split
Y = df_scaled['Class']
X = df_scaled.drop(columns=['Class'])



# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X , Y , test_size=0.3 , random_state=42,  shuffle= True) #70% training and 30% test

# Convert X_train and X_test to numpy arrays
X_train = np.array(X_train)
X_test = np.array(X_test)
feature_names = df.columns
# Create a figure to visualize data distribution
plt.figure(figsize=(12, 8))

# Number of features
num_features = X.shape[1]

# Iterate through each feature and plot its distribution
for i in range(num_features):
    plt.subplot(4, 3, i + 1)

    # Plot histogram and KDE (Kernel Density Estimate)
    sns.histplot(X_train[: , i], kde=True, bins=20, color='blue', alpha=0.6, label='Training data')
    sns.histplot(X_test[: , i], kde=True, bins=20, color='red', alpha=0.6, label='Test data')

    # Add labels and title
    plt.xlabel(feature_names[i])
    plt.ylabel('Frequency')
    plt.title(f'Distribution of {feature_names[i]}')
    plt.legend()

# Adjust layout and show the plot
plt.tight_layout()
plt.show()

# Take the same proportion for the training and test sets
X_train,X_test,y_train,y_test = train_test_split(X , Y , stratify = Y , random_state=42)
y_train_df = pd.DataFrame(y_train, columns=['Class'])
y_test_df = pd.DataFrame(y_test, columns=['Class'])
print("Total number per two classes")
print(df["Class"].value_counts())
print("\n")
print("Total number per two classes for training")
print(y_train_df["Class"].value_counts())
print("\n")
print("Total number per two classes for testing")
print(y_test_df["Class"].value_counts())

#Import svm model
from sklearn import svm

# Create a svm Classifier
# C hyperparameter that controls the distance between the decision boundary and the closest support vectors and minimizing the classification error
clf = svm.SVC(kernel='linear',C=100, probability=True) # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

k = 5  # Number of folds
kf = KFold(n_splits=k, shuffle=True, random_state=42)

# Perform k-fold cross-validation
scores = cross_val_score(clf, X, y, cv=kf)

# Calculate the average score
average_score = np.mean(scores)

# Print the results
print(f'Cross-validation scores: {scores}')
print(f'Average score: {average_score}')

from sklearn.metrics import roc_curve, auc
# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred)

# Calculate the area under the ROC curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for SVM Model')
plt.legend(loc='lower right')
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report

report = classification_report(y_test, y_pred)
print ('Classification report : ')
print(report)

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using Seaborn
plt.figure()
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False)
plt.xlabel('Predicted Class')
plt.ylabel('True Class')
plt.title('Confusion Matrix for SVM Model')
plt.show()

from sklearn.metrics import precision_recall_curve, auc
# Get predicted probabilities for the test set
y_scores = clf.predict_proba(X_test)[:, 1]  # Scores for the positive class

# Calculate precision and recall
precision, recall, thresholds = precision_recall_curve(y_test, y_scores)

# Calculate AUC (Area Under Curve)
pr_auc = auc(recall, precision)

# Plot the Precision-Recall curve
plt.figure()
plt.plot(recall, precision, label=f'PR curve (AUC = {pr_auc:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for SVM Model')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.model_selection import learning_curve
# Define the training set sizes to test
train_sizes, train_scores, test_scores = learning_curve(
    estimator=clf,
    X=X_train,
    y=y_train,
    cv=5,  # Number of cross-validation folds
    train_sizes=np.linspace(0.1, 1.0, 5),
    scoring='accuracy',  # Metric to evaluate
    n_jobs=-1  # Use all available CPU cores
)

# Calculate the mean and standard deviation for the training and test scores
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)
import joblib
joblib.dump(clf, 'svm_model.pkl')
#print(os.path.abspath('svm_model.pkl'))


# Plot the learning curve
plt.figure()
plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', label='Training accuracy')
plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color='blue')
plt.plot(train_sizes, test_scores_mean, 'o-', color='red', label='Validation accuracy')
plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.2, color='red')
plt.xlabel('Training set size')
plt.ylabel('Accuracy')
plt.title('Learning Curve for SVM Model')
plt.legend()
plt.grid(True)
plt.show()


import tkinter as tk
from tkinter import ttk

# Function to predict class based on user input
def predict_class():
    # Get user input from entry widgets
    Area = float(entry_area.get())
    Perimeter = float(entry_perimeter.get())
    Major_Axis_Length = float(entry_major_axis_length.get())
    Minor_Axis_Length = float(entry_minor_axis_length.get())
    Solidity = float(entry_solidity.get())
    Extent = float(entry_extent.get())
    Roundness = float(entry_roundness.get())
    Compactness = float(entry_compactness.get())
    
    # Predict the class using the trained SVM model
    prediction = clf.predict(scaler.transform([[Area, Perimeter, Major_Axis_Length, Minor_Axis_Length, Solidity, Extent, Roundness, Compactness]]))

    # Display the predicted class in the result label widget
    if prediction == 0:
        result_label.config(text='Çerçevelik')
    else:
        result_label.config(text='Ürgüp Sivrisi')

# Create the main application window
root = tk.Tk()
root.title("Seed Classification")

# Create and place labels and entry widgets for user input
tk.Label(root, text="Area:").grid(row=0, column=0, padx=5, pady=5)
entry_area = ttk.Entry(root)
entry_area.grid(row=0, column=1, padx=5, pady=5)

tk.Label(root, text="Perimeter:").grid(row=1, column=0, padx=5, pady=5)
entry_perimeter = ttk.Entry(root)
entry_perimeter.grid(row=1, column=1, padx=5, pady=5)

tk.Label(root, text="Major Axis Length:").grid(row=2, column=0, padx=5, pady=5)
entry_major_axis_length = ttk.Entry(root)
entry_major_axis_length.grid(row=2, column=1, padx=5, pady=5)

tk.Label(root, text="Minor Axis Length:").grid(row=3, column=0, padx=5, pady=5)
entry_minor_axis_length = ttk.Entry(root)
entry_minor_axis_length.grid(row=3, column=1, padx=5, pady=5)

tk.Label(root, text="Solidity:").grid(row=4, column=0, padx=5, pady=5)
entry_solidity = ttk.Entry(root)
entry_solidity.grid(row=4, column=1, padx=5, pady=5)

tk.Label(root, text="Extent:").grid(row=5, column=0, padx=5, pady=5)
entry_extent = ttk.Entry(root)
entry_extent.grid(row=5, column=1, padx=5, pady=5)

tk.Label(root, text="Roundness:").grid(row=6, column=0, padx=5, pady=5)
entry_roundness = ttk.Entry(root)
entry_roundness.grid(row=6, column=1, padx=5, pady=5)

tk.Label(root, text="Compactness:").grid(row=7, column=0, padx=5, pady=5)
entry_compactness = ttk.Entry(root)
entry_compactness.grid(row=7, column=1, padx=5, pady=5)

# Create and place a button to trigger prediction
predict_button = ttk.Button(root, text="Predict", command=predict_class)
predict_button.grid(row=8, columnspan=2, padx=5, pady=10)

# Create a label to display the predicted class
result_label = tk.Label(root, text="")
result_label.grid(row=9, columnspan=2, padx=5, pady=5)

# Run the application
root.mainloop()

